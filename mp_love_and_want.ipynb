{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Firsts\r\n",
    "\r\n",
    "If we consider all the messages ever sent to, and recieved by, _the corpus_, when did each word enter the corpus? Who put it there? What does it say about a person if they put a lot of new words into the corpus, and what even is a word? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\r\n",
    "\r\n",
    "Load up a tonne of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\r\n",
    "import json\r\n",
    "import os\r\n",
    "import pickle\r\n",
    "import random\r\n",
    "import re\r\n",
    "import textwrap\r\n",
    "from pathlib import Path\r\n",
    "from collections import OrderedDict\r\n",
    "\r\n",
    "import matplotlib as mpl\r\n",
    "import matplotlib.dates as mdates\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from matplotlib.font_manager import FontProperties\r\n",
    "from matplotlib.ticker import MultipleLocator, FixedFormatter, FixedLocator\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "from scipy.optimize import curve_fit\r\n",
    "from scipy.spatial import ConvexHull\r\n",
    "\r\n",
    "import message_helpers as mh\r\n",
    "from hangouts_loader import load_hangouts\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\r\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"Segoe UI Emoji\"]\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_name = \"all_convo.pickle\"\r\n",
    "pickle_path = Path(pickle_name)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your name here. This is so that you can take yourself out of some of the graphs. Because these are conversations, naievely, they go A B A B and so on, so you'll be roughly 50% of the messages, which makes other trends hard to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_NAME = \"Ben Doherty\"\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_word(x):\r\n",
    "    try:\r\n",
    "        return x.split()[0]\r\n",
    "    except:\r\n",
    "        return x\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_convo_df = pd.read_pickle(pickle_path)\r\n",
    "print(f\"done: all_convo_df has {all_convo_df.shape[0]} rows\")\r\n",
    "all_convo_df.head()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\r\n",
    "    f\"Overall, there are {len(all_convo_df)}, messages in this dataset. \"\r\n",
    "    f\"These come from about {len(all_convo_df.sender_name.unique())} people, \"\r\n",
    "    f\"covering a period of {str(all_convo_df.datetime.max()-all_convo_df.datetime.min()).split(' days')[0]} days \"\r\n",
    "    f\"between {all_convo_df.datetime.min():%B, %Y} and {all_convo_df.datetime.max():%B, %Y}. \"\r\n",
    "    f\"Over {len(all_convo_df.platform.unique())} platforms:\"\r\n",
    ")\r\n",
    "all_convo_df.platform.value_counts()\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Love, want, hate\r\n",
    "\r\n",
    "What do we love, hate, want, and want to do? Let's look into the text content of the messages a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "love_df = all_convo_df[[\"i love\" in str(x).lower() for x in all_convo_df.content]]\r\n",
    "want_df = all_convo_df[[\"i want\" in str(x).lower() for x in all_convo_df.content]]\r\n",
    "hate_df = all_convo_df[[\"i hate\" in str(x).lower() for x in all_convo_df.content]]\r\n",
    "want_you_df = all_convo_df[\r\n",
    "    [\"i want you\" in str(x).lower() for x in all_convo_df.content]\r\n",
    "]\r\n",
    "\r\n",
    "print(\"love\", love_df.shape[0])\r\n",
    "print(\"want\", want_df.shape[0])\r\n",
    "print(\"hate\", hate_df.shape[0])\r\n",
    "print(\"want you\", want_you_df.shape[0])\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "things_to_love = [\r\n",
    "    x.lower().split(\"i love\")[1].replace(\"!\", \"\").replace(\".\", \"\").strip()\r\n",
    "    for x in love_df.content\r\n",
    "]\r\n",
    "pd.Series(things_to_love).value_counts()[:50].plot.barh()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "things_to_want = [\r\n",
    "    x.lower().split(\"i want\")[1].replace(\"!\", \"\").replace(\".\", \"\")\r\n",
    "    for x in want_df.content\r\n",
    "]\r\n",
    "pd.Series(things_to_want).value_counts()[:50].plot.barh()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_word(x):\r\n",
    "    try:\r\n",
    "        return x.split()[0]\r\n",
    "    except:\r\n",
    "        return x\r\n",
    "\r\n",
    "\r\n",
    "love_vc = pd.Series([first_word(x).strip() for x in things_to_love]).value_counts()\r\n",
    "love_vc[:50].plot.barh()\r\n",
    "plt.title(\"what word comes straight after 'i love'?\\n(All messages, in and out)\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "want_vc = pd.Series(\r\n",
    "    [first_word(x).strip().replace(\".\", \"\").replace(\" \", \"\") for x in things_to_want]\r\n",
    ").value_counts()\r\n",
    "plt.title(\"what word comes straight after 'i want'?\\n(All messages, in and out)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "things_to_want_you = [\r\n",
    "    x.lower().split(\"i want you\")[1].replace(\"!\", \"\").replace(\".\", \"\")\r\n",
    "    for x in want_you_df.content\r\n",
    "]\r\n",
    "pd.Series(things_to_want_you).value_counts()[:50].plot.barh()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "want_you_df.sender_name.value_counts()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "want_you_df[want_you_df.sender_name == \"Charles Ogilvie\"][\r\n",
    "    [\"content\", \"sender_name\", \"datetime\"]\r\n",
    "]\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "things_to_want = [\r\n",
    "    x.lower().split(\"i want\")[1].replace(\"!\", \"\").replace(\".\", \"\")\r\n",
    "    for x in want_df.content\r\n",
    "]\r\n",
    "pd.Series(things_to_want).value_counts()[:50].plot.barh()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "things_to_hate = [\r\n",
    "    x.lower().split(\"i hate\")[1].replace(\"!\", \"\").replace(\".\", \"\")[:100].strip()\r\n",
    "    for x in hate_df.content\r\n",
    "    if \"sending out impersonal\" not in x\r\n",
    "]\r\n",
    "pd.Series(things_to_hate).value_counts()[:50].plot.barh()\r\n",
    "plt.title(\"I hate ...\\nPulled from all messages, in and out\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "love_vc = pd.Series([first_word(x).strip() for x in things_to_love]).value_counts()\r\n",
    "love_vc[:50].plot.barh()\r\n",
    "plt.title(\"what word comes straight after 'i love'?\\n(All messages, in and out)\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "want_vc = pd.Series(\r\n",
    "    [first_word(x).strip().replace(\".\", \"\").replace(\" \", \"\") for x in things_to_want]\r\n",
    ").value_counts()\r\n",
    "want_vc[:50].plot.barh()\r\n",
    "plt.title(\"what word comes straight after 'i want'?\\n(All messages, in and out)\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "love_vc[love_vc > 3].plot.barh()\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look into that list of things we love in a lot more detail. Not the common stuff, this is the unusual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series([x[0] for x in love_vc[love_vc < 3].index.to_list()]).value_counts().plot.barh()\r\n",
    "lvc = pd.Series(things_to_love).value_counts()\r\n",
    "with open(\"love.txt\", \"w\", encoding=\"utf-8\") as f:\r\n",
    "    f.write(\"\\n- \".join(sorted(lvc[lvc < 3].index.to_list())))\r\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0bc9a1eeff4ba10b0800c01e5b0b872b265b92561193d5706117af22821f4cc2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('dp-env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
