{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Firsts\r\n",
    "\r\n",
    "If we consider all the messages ever sent to, and recieved by, _the corpus_, when did each word enter the corpus? Who put it there? What does it say about a person if they put a lot of new words into the corpus, and what even is a word? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\r\n",
    "\r\n",
    "Load up a tonne of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\r\n",
    "import json\r\n",
    "import os\r\n",
    "import pickle\r\n",
    "import random\r\n",
    "import re\r\n",
    "import textwrap\r\n",
    "from pathlib import Path\r\n",
    "from collections import OrderedDict\r\n",
    "\r\n",
    "import matplotlib as mpl\r\n",
    "import matplotlib.dates as mdates\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from matplotlib.font_manager import FontProperties\r\n",
    "from matplotlib.ticker import MultipleLocator, FixedFormatter, FixedLocator\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "from scipy.optimize import curve_fit\r\n",
    "from scipy.spatial import ConvexHull\r\n",
    "\r\n",
    "import message_helpers as mh\r\n",
    "from hangouts_loader import load_hangouts\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\r\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"Segoe UI Emoji\"]\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_name = \"all_convo.pickle\"\r\n",
    "pickle_path = Path(pickle_name)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your name here. This is so that you can take yourself out of some of the graphs. Because these are conversations, naievely, they go A B A B and so on, so you'll be roughly 50% of the messages, which makes other trends hard to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_NAME = \"Ben Doherty\"\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_convo_df = pd.read_pickle(pickle_path)\r\n",
    "print(f\"done: all_convo_df has {all_convo_df.shape[0]} rows\")\r\n",
    "all_convo_df.head()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\r\n",
    "    f\"Overall, there are {len(all_convo_df)}, messages in this dataset. \"\r\n",
    "    f\"These come from about {len(all_convo_df.sender_name.unique())} people, \"\r\n",
    "    f\"covering a period of {str(all_convo_df.datetime.max()-all_convo_df.datetime.min()).split(' days')[0]} days \"\r\n",
    "    f\"between {all_convo_df.datetime.min():%B, %Y} and {all_convo_df.datetime.max():%B, %Y}. \"\r\n",
    "    f\"Over {len(all_convo_df.platform.unique())} platforms:\"\r\n",
    ")\r\n",
    "all_convo_df.platform.value_counts()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_seconds(dt):\r\n",
    "    t = dt.time()\r\n",
    "    seconds = (t.hour * 60 + t.minute) * 60 + t.second\r\n",
    "    return seconds\r\n",
    "\r\n",
    "\r\n",
    "all_convo_df[\"date\"] = all_convo_df.datetime.apply(lambda x: x.date())\r\n",
    "all_convo_df[\"time\"] = all_convo_df.datetime.apply(lambda x: x.time())\r\n",
    "all_convo_df[\"seconds\"] = all_convo_df.datetime.apply(time_to_seconds)\r\n",
    "all_convo_df.sample(5)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEXY_WORDS = [\r\n",
    "    \"balls\",\r\n",
    "    \"clit\",\r\n",
    "    \"cock\",\r\n",
    "    \"dick\",\r\n",
    "    \"dildo\",\r\n",
    "    \"fuck me\",\r\n",
    "    \"fuck you\",\r\n",
    "    # \"fuck\", # fuck overwhealms everything (at least for me)\r\n",
    "    \"head\",\r\n",
    "    \"lick\",\r\n",
    "    \"lips\",\r\n",
    "    \"masterbat\",\r\n",
    "    \"nipple\",\r\n",
    "    \"orgasm\",\r\n",
    "    \"play\",\r\n",
    "    \"pussy\",\r\n",
    "    \"spank\",\r\n",
    "    \"suck\",\r\n",
    "    \"toys\",\r\n",
    "    \"vibrator\",\r\n",
    "    \"wand\",\r\n",
    "    \"wank\",\r\n",
    "]\r\n",
    "\r\n",
    "\r\n",
    "def is_sexy(content):\r\n",
    "    try:\r\n",
    "        if any(x.lower() in content for x in SEXY_WORDS):\r\n",
    "            return \"sexy\"\r\n",
    "    except:\r\n",
    "        pass\r\n",
    "    return \"not\"\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_convo_df[\"sexy\"] = all_convo_df.content.apply(is_sexy)\r\n",
    "\r\n",
    "fig = plt.figure()\r\n",
    "ax = fig.add_subplot(111)\r\n",
    "for name, data in all_convo_df.groupby(\"sexy\"):\r\n",
    "    if name == \"sexy\":\r\n",
    "        ax.scatter(data.date, data.seconds, s=30, alpha=0.5, c=\"red\", marker=\"x\")\r\n",
    "    else:\r\n",
    "        ax.scatter(data.date, data.seconds, s=10, alpha=0.1, c=\"blue\", marker=\".\")\r\n",
    "\r\n",
    "# ax.yaxis_date()\r\n",
    "seconds_in_a_day = 24 * 60 * 60\r\n",
    "ax.yaxis.set_major_locator(plt.MaxNLocator(30))\r\n",
    "# plt.yticks(plt.yticks()[0], [datetime.timedelta(seconds=t)  for t in plt.yticks()[0]])\r\n",
    "plt.ylim([0, seconds_in_a_day])\r\n",
    "\r\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(30))\r\n",
    "fig.autofmt_xdate()\r\n",
    "# plt.xlim(['2020-07-18', '2021-07-21'])\r\n",
    "\r\n",
    "plt.suptitle(\"When do we talk sexy?\")\r\n",
    "plt.title(\"\\n\".join(textwrap.wrap(f\"Occurance of {', '.join(SEXY_WORDS)}\", 100)))\r\n",
    "plt.ylabel(\"seconds after midnight GMT\")\r\n",
    "\r\n",
    "plt.show()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = 50\r\n",
    "\r\n",
    "pool = \" \".join(all_convo_df[all_convo_df.sexy == \"sexy\"].content.to_list())\r\n",
    "clean = re.sub(\r\n",
    "    mh.PUNCTUATION_REGEX,\r\n",
    "    \" \",\r\n",
    "    pool,\r\n",
    "    flags=re.VERBOSE,  # and replace it with a single space\r\n",
    ")\r\n",
    "stopped = [w.lower() for w in clean.split() if w.lower() not in mh.STOP_WORDS]\r\n",
    "vc = pd.Series(stopped).value_counts()\r\n",
    "vc[:top].plot.barh()\r\n",
    "plt.title(f'Top {top} most common words in \"sexy\" messages')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = \" \".join([str(x) for x in all_convo_df.content])\r\n",
    "clean = re.sub(\r\n",
    "    mh.PUNCTUATION_REGEX,\r\n",
    "    \" \",\r\n",
    "    pool,\r\n",
    "    flags=re.VERBOSE,  # and replace it with a single space\r\n",
    ")\r\n",
    "stopped = [w.lower() for w in clean.split() if w.lower() not in mh.STOP_WORDS]\r\n",
    "vc = pd.Series(stopped).value_counts()\r\n",
    "vc[:top].plot.barh()\r\n",
    "plt.title(f\"Top {top} most common words in all messages\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = {}\r\n",
    "for name, df in all_convo_df.groupby(\"sender_name\"):\r\n",
    "    if df.shape[0] > 1000:\r\n",
    "        vc = df.sexy.value_counts()\r\n",
    "        ratios[name] = (vc.get(\"sexy\", 1)) / vc[\"not\"]\r\n",
    "highly_sexy = pd.Series(ratios).sort_values()\r\n",
    "highly_sexy.plot.barh()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(highly_sexy.index)\r\n",
    "highly_sexy_df = all_convo_df[\r\n",
    "    [x in list(highly_sexy.index) for x in all_convo_df.sender_name]\r\n",
    "]\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurances = []\r\n",
    "for name, df in highly_sexy_df.groupby(\"sender_name\"):\r\n",
    "    d = {\"name\": name}\r\n",
    "    pool = \" \".join([str(x) for x in df.content])\r\n",
    "    for w in SEXY_WORDS:\r\n",
    "        oc = pool.count(w)\r\n",
    "        d[w] = oc\r\n",
    "    occurances.append(d)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = pd.DataFrame(occurances)\r\n",
    "sdf = sdf.set_index(\"name\")\r\n",
    "sdf.head()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_normed = sdf.div(sdf.sum(axis=1), axis=0)\r\n",
    "sdf_normed.plot.barh(edgecolor=\"none\")\r\n",
    "plt.title(\"Occurances of these words (normalised per person)\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf[sdf.index != MY_NAME].plot.barh(edgecolor=\"none\")\r\n",
    "plt.title(\"Occurances of these words (not normalised per person)\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [\r\n",
    "    MY_NAME,\r\n",
    "    \"Irina Belova\",\r\n",
    "    \"Ivana Kuzmanovska\",\r\n",
    "    \"Lucy Rimmer\",\r\n",
    "    \"Maddie Johanson\",\r\n",
    "    \"Meike Wijers\",\r\n",
    "]\r\n",
    "sdf_normed.loc[p].plot.barh(\r\n",
    "    edgecolor=\"none\",\r\n",
    "    width=0.7,\r\n",
    ")\r\n",
    "plt.title(f\"Occurances of these words in messages from \\n{p} (normalised)\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.sum(axis=0).plot.barh()\r\n",
    "plt.title(\"General occurance of these words\")\r\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0bc9a1eeff4ba10b0800c01e5b0b872b265b92561193d5706117af22821f4cc2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('dp-env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
