{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the conversations\r\n",
    "\r\n",
    "This is a bit trickier as you need to do something with all the conversations you're loading up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\r\n",
    "import json\r\n",
    "import os\r\n",
    "import pickle\r\n",
    "import random\r\n",
    "import re\r\n",
    "import textwrap\r\n",
    "from pathlib import Path\r\n",
    "from collections import OrderedDict\r\n",
    "\r\n",
    "import matplotlib as mpl\r\n",
    "import matplotlib.dates as mdates\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from matplotlib.font_manager import FontProperties\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "from scipy.optimize import curve_fit\r\n",
    "from scipy.spatial import ConvexHull\r\n",
    "\r\n",
    "import message_helpers as mh\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20, 20)\r\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"Segoe UI Emoji\"]\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_name = \"all_convo.pickle\"\r\n",
    "pickle_path = Path(pickle_name)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_obj(obj):\r\n",
    "    for key in obj:\r\n",
    "        if isinstance(obj[key], str):\r\n",
    "            obj[key] = obj[key].encode(\"latin_1\").decode(\"utf-8\")\r\n",
    "        elif isinstance(obj[key], list):\r\n",
    "            obj[key] = list(\r\n",
    "                map(\r\n",
    "                    lambda x: x\r\n",
    "                    if type(x) != str\r\n",
    "                    else x.encode(\"latin_1\").decode(\"utf-8\"),\r\n",
    "                    obj[key],\r\n",
    "                )\r\n",
    "            )\r\n",
    "        pass\r\n",
    "    return obj\r\n",
    "\r\n",
    "\r\n",
    "def sumarise_convo(name, data, verbose=False):\r\n",
    "    words = {}\r\n",
    "    words[name] = data.content.str.cat(sep=\" \")\r\n",
    "    wordcount = len(words[name].split(\" \"))\r\n",
    "\r\n",
    "    unique_words = set(words[name].split(\" \"))\r\n",
    "\r\n",
    "    pool = \" \".join([str(x) for x in data.content.to_list()]).lower()\r\n",
    "    clean = re.sub(mh.PUNCTUATION_REGEX, \" \", pool, flags=re.VERBOSE)\r\n",
    "    # and replace it with a single space\r\n",
    "    stopped = list(set([w for w in clean.split() if w not in mh.STOP_WORDS]))\r\n",
    "\r\n",
    "    if verbose:\r\n",
    "        print(\r\n",
    "            f\"{name} wrote {wordcount} words ({len(words[name])} characters)\"\r\n",
    "            f\" and used {len(stopped)} different words.\"\r\n",
    "        )\r\n",
    "    return {\r\n",
    "        \"participant\": name,\r\n",
    "        \"wordcount\": wordcount,\r\n",
    "        \"unique_words\": len(unique_words),\r\n",
    "        \"cleaned_unique\": len(stopped),\r\n",
    "    }\r\n",
    "\r\n",
    "\r\n",
    "def get_message_length(message):\r\n",
    "    if type(message) is str:\r\n",
    "        return len(message)\r\n",
    "    else:\r\n",
    "        return len(str(message))\r\n",
    "\r\n",
    "\r\n",
    "def replace_typographic_apostrophy(message):\r\n",
    "    if type(message) is str:\r\n",
    "        return message.replace(\"’\", \"'\")\r\n",
    "    else:\r\n",
    "        return message\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_whole_inbox(rootdir, platform=\"Facebook\"):\r\n",
    "    conversations = []\r\n",
    "    for d in os.listdir(rootdir):\r\n",
    "        conversations.append(d)\r\n",
    "    print(f\"There are {len(conversations)} conversations to look at from {platform}.\")\r\n",
    "    # conversations\r\n",
    "\r\n",
    "    convo_df_list = []\r\n",
    "\r\n",
    "    if not pickle_path.is_file():\r\n",
    "        for convo in os.listdir(rootdir):\r\n",
    "            for f in os.listdir(os.path.join(rootdir, convo)):\r\n",
    "                try:\r\n",
    "                    message_list = []\r\n",
    "                    path = os.path.join(os.path.join(rootdir, convo, f))\r\n",
    "                    if Path(path).is_file():\r\n",
    "                        with open(path, \"r\") as fb_data:\r\n",
    "                            messages = json.load(fb_data, object_hook=parse_obj)\r\n",
    "                            message_list.extend(messages[\"messages\"])\r\n",
    "\r\n",
    "                    if len(message_list) != 0:\r\n",
    "                        df = pd.DataFrame(message_list)\r\n",
    "                        df[\"source_convo\"] = convo\r\n",
    "                        df[\"datetime\"] = df.timestamp_ms.apply(\r\n",
    "                            lambda x: datetime.datetime.fromtimestamp(x / 1000.0)\r\n",
    "                        )\r\n",
    "\r\n",
    "                        if \"content\" in df.columns:\r\n",
    "                            df[\"message_length\"] = df.content.apply(get_message_length)\r\n",
    "                            df.content = df.content.apply(\r\n",
    "                                replace_typographic_apostrophy\r\n",
    "                            )\r\n",
    "                        else:\r\n",
    "                            df[\"message_length\"] = 0\r\n",
    "                            df[\"content\"] = np.nan\r\n",
    "\r\n",
    "                        df[\"platform\"] = platform\r\n",
    "\r\n",
    "                        convo_df_list.append(df)\r\n",
    "\r\n",
    "                except Exception as e:\r\n",
    "                    print(\"exception\", convo, e)\r\n",
    "    return convo_df_list\r\n",
    "\r\n",
    "\r\n",
    "fb_rootdir = \"fb_data\\messages\\inbox\"\r\n",
    "fb_convo_df_list = load_whole_inbox(fb_rootdir, platform=\"Facebook\")\r\n",
    "ig_rootdir = \"ig_data\\inbox\"\r\n",
    "ig_convo_df_list = load_whole_inbox(ig_rootdir, platform=\"Instagram\")\r\n",
    "convo_df_list = fb_convo_df_list + ig_convo_df_list\r\n",
    "len(convo_df_list)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pickle_path.is_file():\r\n",
    "    all_convo_df = pd.read_pickle(pickle_path)\r\n",
    "else:\r\n",
    "    all_convo_df = pd.concat(convo_df_list)\r\n",
    "    pd.to_pickle(all_convo_df, pickle_path)\r\n",
    "    all_convo_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_stop(content, as_list=False):\r\n",
    "    try:\r\n",
    "        clean = re.sub(\r\n",
    "            mh.PUNCTUATION_REGEX,\r\n",
    "            \" \",\r\n",
    "            content,\r\n",
    "            flags=re.VERBOSE,  # and replace it with a single space\r\n",
    "        )\r\n",
    "        stopped = [w.lower() for w in clean.split() if w.lower() not in mg.STOP_WORDS]\r\n",
    "        # print(content, \"=>\", stopped)\r\n",
    "        if as_list:\r\n",
    "            return stopped\r\n",
    "        else:\r\n",
    "            return \" \".join(stopped)\r\n",
    "    except Exception as e:\r\n",
    "        # print(content, e)\r\n",
    "        return content\r\n",
    "\r\n",
    "\r\n",
    "all_convo_df[\"clean_content\"] = all_convo_df.content.apply(clean_and_stop)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = {}\r\n",
    "# for name, data in df.groupby(\"sender_name\"):\r\n",
    "#     words[name] = data.content.str.cat(sep=\" \")\r\n",
    "#     wordcount = len(words[name].split(\" \"))\r\n",
    "#     # print(f\"{name} wrote {wordcount} words ({len(words[name])} characters)\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, df in all_convo_df.groupby(\"platform\"):\r\n",
    "#     vc = df.sender_name.value_counts()\r\n",
    "#     print(vc[vc>100].index)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_names(input_name):\r\n",
    "    byron = \"Byron Sullivan\"\r\n",
    "    charlie = \"Charlie\"\r\n",
    "    karin = \"Karin\"\r\n",
    "    ivana = \"Ivana Kuzmanovska\"\r\n",
    "    julz = \"Jülz Milthorpe\"\r\n",
    "    jess = \"Jess Howard\"\r\n",
    "    jodie = \"Jodie Hinton\"\r\n",
    "    tones = \"Antonia Sheil\"\r\n",
    "    annisa = \"Annisa Rivera Rizal\"\r\n",
    "    thesaurus = {\r\n",
    "        \"Byron Sullivan\": byron,\r\n",
    "        \"Byron\": byron,\r\n",
    "        \"Thearlaich Ogilive\": charlie,\r\n",
    "        \"Charles OGILVIE\": charlie,\r\n",
    "        \"Karin Frost\": karin,\r\n",
    "        \"karin ke\": karin,\r\n",
    "        \"Ivana Kuzmanovska\": ivana,\r\n",
    "        \"ivana kuzmanovska\": ivana,\r\n",
    "        \"Jülz\": julz,\r\n",
    "        \"Jülz Milthorpe\": julz,\r\n",
    "        \"jesshoward\": jess,\r\n",
    "        \"Jess Howard\": jess,\r\n",
    "        \"Jodie\": jodie,\r\n",
    "        \"Tones\": tones,\r\n",
    "        \"annisarivera\": annisa,\r\n",
    "    }\r\n",
    "    new_name = thesaurus.get(input_name, input_name)\r\n",
    "    # if new_name != input_name:\r\n",
    "    #     print(f\"renamed {input_name} to {new_name}\")\r\n",
    "    return new_name\r\n",
    "\r\n",
    "\r\n",
    "all_convo_df[\"input_names\"] = all_convo_df.sender_name\r\n",
    "all_convo_df.sender_name = all_convo_df.sender_name.apply(fold_names)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_convo_df.shape)\r\n",
    "all_convo_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_meta = []\r\n",
    "for name, data in all_convo_df.groupby(\"sender_name\"):\r\n",
    "    conv_meta.append(sumarise_convo(name, data))\r\n",
    "meta_df = pd.DataFrame(conv_meta)\r\n",
    "meta_df[\"ratio\"] = meta_df.apply(\r\n",
    "    lambda row: row.wordcount / (row.cleaned_unique + 1), axis=1\r\n",
    ")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\r\n",
    "ax = plt.gca()\r\n",
    "# plt.scatter(meta_df.wordcount, meta_df.unique_words)\r\n",
    "ax.scatter(meta_df.wordcount, meta_df.cleaned_unique)\r\n",
    "plt.xlabel(\"Wordcount\")\r\n",
    "plt.ylabel(\"Number of unique words\")\r\n",
    "plt.xlim([0, 380000])\r\n",
    "plt.ylim([0, 18000])\r\n",
    "\r\n",
    "for i, row in meta_df.iterrows():\r\n",
    "    if row.wordcount > 15000:\r\n",
    "        # if row.wordcount > 15000:\r\n",
    "        #     right = 60\r\n",
    "        # else:\r\n",
    "        #     right = 500\r\n",
    "        plt.annotate(\r\n",
    "            row.participant,\r\n",
    "            (row.wordcount, row.cleaned_unique),\r\n",
    "            size=10,\r\n",
    "            xycoords=\"data\",\r\n",
    "            xytext=(\r\n",
    "                random.randint(50, 130) * random.sample(range(-1, 1), k=1)[0],\r\n",
    "                random.randint(50, 60) * random.sample(range(-1, 1), k=1)[0],\r\n",
    "            ),\r\n",
    "            textcoords=\"offset points\",\r\n",
    "            arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=-0.2\"),\r\n",
    "        )\r\n",
    "\r\n",
    "# # define the true objective function\r\n",
    "# def objective(x, a, b, c):\r\n",
    "# \treturn a * x + b * x**2 + c\r\n",
    "# x=meta_df.wordcount\r\n",
    "# y=meta_df.cleaned_unique\r\n",
    "# # curve fit\r\n",
    "# popt, _ = curve_fit(objective, x, y)\r\n",
    "# # summarize the parameter values\r\n",
    "# a, b, c = popt\r\n",
    "# print('y = %.5f * x + %.5f * x^2 + %.5f' % (a, b, c))\r\n",
    "\r\n",
    "# # define a sequence of inputs between the smallest and largest known inputs\r\n",
    "# x_line = np.arange(min(x), max(x), 1)\r\n",
    "# # calculate the output for the range\r\n",
    "# y_line = objective(x_line, a, b, c)\r\n",
    "# # create a line plot for the mapping function\r\n",
    "# plt.plot(x_line, y_line, '--', color='red')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df[meta_df.wordcount > 5000].set_index(\r\n",
    "    \"participant\"\r\n",
    ").ratio.sort_values().plot.barh()\r\n",
    "plt.title(\r\n",
    "    \"Ratio of wordcount to unique words count\\n(only showing those with word counts over 5k)\"\r\n",
    ")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = all_convo_df.sender_name.value_counts()\r\n",
    "lb, ub = (500, 100000)\r\n",
    "vc[(vc > lb) & (vc < ub)].plot.barh(\r\n",
    "    title=f\"Number of messages sent (between {lb} & {ub})\"\r\n",
    ")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatty_people = all_convo_df.sender_name.value_counts() > 1000\r\n",
    "all_convo_df[\"chatty_people\"] = [chatty_people[x] for x in all_convo_df.sender_name]\r\n",
    "all_convo_df.sample(10)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting time that might show sleep\r\n",
    "\r\n",
    "This is a bit nasty, I don't really like it, but it seems to work. There _must_ be a better way.\r\n",
    "\r\n",
    "Convert the time component of the datetime to just-date and just-time (but in seconds, as a number) and then plot that.\r\n",
    "\r\n",
    "The y axis is nasty becasue it doesn't show "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_seconds(dt):\r\n",
    "    t = dt.time()\r\n",
    "    seconds = (t.hour * 60 + t.minute) * 60 + t.second\r\n",
    "    return seconds\r\n",
    "\r\n",
    "\r\n",
    "all_convo_df[\"date\"] = all_convo_df.datetime.apply(lambda x: x.date())\r\n",
    "all_convo_df[\"time\"] = all_convo_df.datetime.apply(lambda x: x.time())\r\n",
    "all_convo_df[\"seconds\"] = all_convo_df.datetime.apply(time_to_seconds)\r\n",
    "all_convo_df.sample(5)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\r\n",
    "ax = fig.add_subplot(111)\r\n",
    "for name, df in all_convo_df.groupby(\"platform\"):\r\n",
    "    ax.scatter(df.date, df.seconds, s=20, alpha=0.04, label=name)\r\n",
    "ax.yaxis_date()\r\n",
    "fig.autofmt_xdate()\r\n",
    "plt.title(\"all messages in and out\")\r\n",
    "plt.ylabel(\"seconds after midnight GMT\")\r\n",
    "\r\n",
    "plt.show()\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this makes sense to me, but it's a bit gross. The y axis is all messed up, it should be showing time, not number of seconds. I'm also not sure if time goes forward up or down the page.\r\n",
    "\r\n",
    "It'd be good to work out a way of identifying sleep periods. Maybe that's a period that starts after 10pm that's offline for more than 4 hours?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (30, 30)\r\n",
    "\r\n",
    "cut = 500\r\n",
    "labels = []\r\n",
    "odd_df = None\r\n",
    "\r\n",
    "fontP = FontProperties()\r\n",
    "fontP.set_size(\"x-small\")\r\n",
    "all_initials = []\r\n",
    "\r\n",
    "fig = plt.figure()\r\n",
    "ax = fig.add_subplot(111)\r\n",
    "for name, df in all_convo_df.groupby(\"sender_name\"):\r\n",
    "    if df.shape[0] > cut:\r\n",
    "        initials = \"\".join([n[0] for n in name.split()]).upper()\r\n",
    "        if initials in all_initials:\r\n",
    "            print(\"uh oh, double up on\", initials, name)\r\n",
    "            initials = (\r\n",
    "                \"\".join([n[0] for n in name.split()]).upper() + name.split()[-1][1]\r\n",
    "            )\r\n",
    "            print(\"replaced with\", initials)\r\n",
    "        else:\r\n",
    "            all_initials.append(initials)\r\n",
    "\r\n",
    "        label = f\"{name} ({initials}, {df.shape[0]})\"\r\n",
    "\r\n",
    "        if name == \"Ben Doherty\":\r\n",
    "            marker = \",\"\r\n",
    "            ax.scatter(\r\n",
    "                df.date,\r\n",
    "                df.seconds,\r\n",
    "                s=0.3,\r\n",
    "                alpha=0.3,\r\n",
    "                linewidth=0,\r\n",
    "                label=label,\r\n",
    "                marker=marker,\r\n",
    "            )\r\n",
    "        elif len(initials) > 0:\r\n",
    "            marker = f\"${initials}$\"\r\n",
    "            ax.scatter(\r\n",
    "                df.date,\r\n",
    "                df.seconds,\r\n",
    "                s=10 if len(initials) == 2 else 15,\r\n",
    "                alpha=0.2,\r\n",
    "                linewidth=0,\r\n",
    "                label=label,\r\n",
    "                marker=marker,\r\n",
    "            )\r\n",
    "        else:\r\n",
    "            # marker = \"1\"\r\n",
    "            # print(name, \"odd one\", df.content.head(10))\r\n",
    "            odd_df = df\r\n",
    "\r\n",
    "        labels.append(label)\r\n",
    "    else:\r\n",
    "        ax.scatter(\r\n",
    "            df.date,\r\n",
    "            df.seconds,\r\n",
    "            s=15,\r\n",
    "            alpha=0.1,\r\n",
    "            marker=\"x\",\r\n",
    "        )\r\n",
    "ax.yaxis_date()\r\n",
    "fig.autofmt_xdate()\r\n",
    "plt.title(\"all messages in and out\")\r\n",
    "plt.ylabel(\"seconds after midnight GMT\")\r\n",
    "leg = plt.legend(\r\n",
    "    title=f\"People with more\\nthan {cut} messages\",\r\n",
    "    bbox_to_anchor=(1.05, 1),\r\n",
    "    loc=\"upper left\",\r\n",
    "    prop=fontP,\r\n",
    ")\r\n",
    "for lh in leg.legendHandles:\r\n",
    "    lh.set_alpha(1)\r\n",
    "\r\n",
    "plt.savefig(\"all_messages.svg\")\r\n",
    "# plt.show()\r\n",
    "print(labels)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.lmplot(\r\n",
    "    x=\"date\",\r\n",
    "    y=\"seconds\",\r\n",
    "    data=all_convo_df[all_convo_df[\"chatty_people\"]],\r\n",
    "    # data=all_convo_df,\r\n",
    "    hue=\"sender_name\",\r\n",
    "    fit_reg=False,\r\n",
    "    legend=True,\r\n",
    "    palette=\"Set2\",\r\n",
    "    col=\"sender_name\",\r\n",
    "    col_wrap=4,\r\n",
    "    scatter_kws=dict(s=80, alpha=0.2),\r\n",
    ")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (15, 15)})\r\n",
    "plot = sns.lmplot(\r\n",
    "    x=\"date\",\r\n",
    "    y=\"seconds\",\r\n",
    "    data=all_convo_df[all_convo_df.sender_name != \"Ben Doherty\"],\r\n",
    "    hue=\"sender_name\",\r\n",
    "    markers=\"x\",\r\n",
    "    fit_reg=False,\r\n",
    "    legend=False,\r\n",
    "    palette=\"Set1\",\r\n",
    "    scatter_kws=dict(s=30, alpha=0.1),\r\n",
    "    height=20,\r\n",
    "    aspect=20 / 20,\r\n",
    ")\r\n",
    "# plt.xticks(rotation=45);\r\n",
    "plt.savefig(\"all_incoming.svg\")\r\n",
    "plt.savefig(\"all_incoming.png\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = all_convo_df[all_convo_df.sender_name != \"Ben Doherty\"]\r\n",
    "data = data[data.chatty_people]\r\n",
    "print(data.shape)\r\n",
    "data.sample(3)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (10, 10)})\r\n",
    "fig, ax = plt.subplots()\r\n",
    "g = sns.scatterplot(\r\n",
    "    x=\"date\",\r\n",
    "    y=\"seconds\",\r\n",
    "    data=data,\r\n",
    "    hue=\"sender_name\",\r\n",
    "    legend=False,\r\n",
    "    palette=\"Set1\",\r\n",
    "    s=30,\r\n",
    "    alpha=0.1,\r\n",
    "    ax=ax,\r\n",
    ")\r\n",
    "# g.legend(bbox_to_anchor=(1.5, 1))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encircle(x, y, ax=None, **kw):\r\n",
    "    if not ax:\r\n",
    "        ax = plt.gca()\r\n",
    "    p = np.c_[x, y]\r\n",
    "    hull = ConvexHull(p)\r\n",
    "    poly = plt.Polygon(p[hull.vertices, :], **kw)\r\n",
    "    ax.add_patch(poly)\r\n",
    "\r\n",
    "\r\n",
    "fig, ax = plt.subplots()\r\n",
    "for x, d in data.groupby(\"sender_name\"):\r\n",
    "    if d.shape[0] > 4000:\r\n",
    "        m, b = np.polyfit(d.timestamp_ms, d.seconds, 1)\r\n",
    "        plt.plot(d.timestamp_ms, m * d.timestamp_ms + b)\r\n",
    "        col = plt.gca().lines[-1].get_color()\r\n",
    "        sc = ax.scatter(d.timestamp_ms, d.seconds, s=10, alpha=0.4, label=x, color=col)\r\n",
    "        encircle(d.timestamp_ms, d.seconds, ax=ax, ec=col, fc=\"none\")\r\n",
    "        plt.annotate(x, (d.timestamp_ms.mean(), d.seconds.mean()), size=10, color=col)\r\n",
    "\r\n",
    "plt.show()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_out_df = all_convo_df[all_convo_df.sender_name == \"Ben Doherty\"]\r\n",
    "bd_out_df.set_index(\"datetime\").groupby(pd.Grouper(freq=\"M\")).count().sender_name.plot()\r\n",
    "plt.title(\"Messages sent per Month\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\r\n",
    "for x, d in all_convo_df.groupby(\"sender_name\"):\r\n",
    "    if d.shape[0] > 4000 and x != \"Ben Doherty\":\r\n",
    "        per_period = (\r\n",
    "            d.set_index(\"datetime\").groupby(pd.Grouper(freq=\"2m\")).count().sender_name\r\n",
    "        )\r\n",
    "        per_period.plot()\r\n",
    "        col = plt.gca().lines[-1].get_color()\r\n",
    "        plt.annotate(x, (per_period.idxmax(), per_period.max()), size=10, color=col)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOO_WORDS = [\r\n",
    "    \"poop\",\r\n",
    "    \"home\",\r\n",
    "    \"doughnut\",\r\n",
    "]\r\n",
    "\r\n",
    "\r\n",
    "def is_soo(content):\r\n",
    "    try:\r\n",
    "        if any(x.lower() in content for x in SOO_WORDS):\r\n",
    "            return \"soo\"\r\n",
    "    except:\r\n",
    "        pass\r\n",
    "    return \"not\"\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_convo_df[\"soo\"] = all_convo_df.content.apply(is_soo)\r\n",
    "\r\n",
    "fig = plt.figure()\r\n",
    "ax = fig.add_subplot(111)\r\n",
    "for name, data in all_convo_df.groupby(\"soo\"):\r\n",
    "    if name == \"soo\":\r\n",
    "        ax.scatter(data.date, data.seconds, s=30, alpha=0.5, c=\"red\", marker=\"x\")\r\n",
    "    else:\r\n",
    "        ax.scatter(data.date, data.seconds, s=10, alpha=0.1, c=\"blue\", marker=\".\")\r\n",
    "\r\n",
    "# ax.yaxis_date()\r\n",
    "seconds_in_a_day = 24 * 60 * 60\r\n",
    "ax.yaxis.set_major_locator(plt.MaxNLocator(30))\r\n",
    "# plt.yticks(plt.yticks()[0], [datetime.timedelta(seconds=t)  for t in plt.yticks()[0]])\r\n",
    "plt.ylim([0, seconds_in_a_day])\r\n",
    "\r\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(30))\r\n",
    "fig.autofmt_xdate()\r\n",
    "# plt.xlim(['2020-07-18', '2021-07-21'])\r\n",
    "\r\n",
    "plt.suptitle(\"When do we talk soo?\")\r\n",
    "plt.title(f\"Occurance of {', '.join(SOO_WORDS)}\")\r\n",
    "\r\n",
    "plt.show()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = 50\r\n",
    "\r\n",
    "pool = \" \".join(all_convo_df[all_convo_df.soo == \"soo\"].content.to_list())\r\n",
    "clean = re.sub(\r\n",
    "    mh.PUNCTUATION_REGEX, \" \", pool, flags=re.VERBOSE  # and replace it with a single space\r\n",
    ")\r\n",
    "stopped = [w.lower() for w in clean.split() if w.lower() not in mh.STOP_WORDS]\r\n",
    "vc = pd.Series(stopped).value_counts()\r\n",
    "vc[:top].plot.barh()\r\n",
    "plt.title(f'Top {top} most common words in \"soo\" messages')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = \" \".join([str(x) for x in all_convo_df.content])\r\n",
    "clean = re.sub(\r\n",
    "    mh.PUNCTUATION_REGEX, \" \", pool, flags=re.VERBOSE  # and replace it with a single space\r\n",
    ")\r\n",
    "stopped = [w.lower() for w in clean.split() if w.lower() not in mh.STOP_WORDS]\r\n",
    "vc = pd.Series(stopped).value_counts()\r\n",
    "vc[:top].plot.barh()\r\n",
    "plt.title(f\"Top {top} most common words in all messages\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = {}\r\n",
    "for name, df in all_convo_df.groupby(\"sender_name\"):\r\n",
    "    if df.shape[0] > 1000:\r\n",
    "        vc = df.soo.value_counts()\r\n",
    "        ratios[name] = (vc.get(\"soo\", 1)) / vc[\"not\"]\r\n",
    "highly_soo = pd.Series(ratios).sort_values()\r\n",
    "highly_soo.plot.barh()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(highly_soo.index)\r\n",
    "highly_soo_df = all_convo_df[\r\n",
    "    [x in list(highly_soo.index) for x in all_convo_df.sender_name]\r\n",
    "]\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurances = []\r\n",
    "for name, df in highly_soo_df.groupby(\"sender_name\"):\r\n",
    "    d = {\"name\": name}\r\n",
    "    pool = \" \".join([str(x) for x in df.content])\r\n",
    "    for w in SOO_WORDS:\r\n",
    "        oc = pool.count(w)\r\n",
    "        d[w] = oc\r\n",
    "    occurances.append(d)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = pd.DataFrame(occurances)\r\n",
    "sdf = sdf.set_index(\"name\")\r\n",
    "sdf.head()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_normed = sdf.div(sdf.sum(axis=1), axis=0)\r\n",
    "sdf_normed.plot.barh(edgecolor=\"none\")\r\n",
    "plt.title(\"Occurances of these words (normalised per person)\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf[sdf.index != \"Ben Doherty\"].plot.barh(edgecolor=\"none\")\r\n",
    "plt.title(\"Occurances of these words (not normalised per person)\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [\r\n",
    "    \"Ben Doherty\",\r\n",
    "    \"Ivana Kuzmanovska\",\r\n",
    "    \"More People\"\r\n",
    "]\r\n",
    "# This will fail because there isnt' a person in the dataset called \"More People\"\r\n",
    "sdf_normed.loc[p].plot.barh(edgecolor=\"none\", width=0.7,)\r\n",
    "plt.title(f\"Occurances of these words in messages from \\n{p} (normalised)\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.sum(axis=0).plot.barh()\r\n",
    "plt.title(\"General occurance of these words\")\r\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0bc9a1eeff4ba10b0800c01e5b0b872b265b92561193d5706117af22821f4cc2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('dp-env': venv)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
